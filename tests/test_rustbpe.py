import rustbpe
import time
import os
from pathlib import Path

def test_rustbpe():
    # 1. å®ä¾‹åŒ–
    try:
        tokenizer = rustbpe.Tokenizer()
        print("âœ… RUSTBPE Tokenizer å®ä¾‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å®ä¾‹åŒ–å¤±è´¥: {e}")
        return

    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir,'taylorswift.txt')
    data = Path(data_path).read_text(encoding='utf-8')
    
    # 3. è®­ç»ƒ
    # è¯è¡¨å¤§å°è®¾ä¸º 300 (åŸºç¡€ 256 å­—èŠ‚ + 44 ä¸ªåˆå¹¶è§„åˆ™)
    print("â³ å¼€å§‹è®­ç»ƒ (vocab_size=300)...")
    t0 = time.time()
    try:
        tokenizer.train_from_iterator(data, 300)
        dt = time.time() - t0
        print(f"âœ… è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {dt:.4f}s")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return

    # 4. ç¼–ç æµ‹è¯•
    test_str = "hello world rust is cool"
    try:
        ids = tokenizer.encode(test_str)
        print(f"âœ… ç¼–ç ç»“æœ: '{test_str}' -> {ids}")
        print(f"   åŸå§‹é•¿åº¦: {len(test_str)}, Token æ•°é‡: {len(ids)}")
    except Exception as e:
        print(f"âŒ ç¼–ç å¤±è´¥: {e}")
        return

    print("\nğŸ‰ æ­å–œï¼Rust Tokenizer æ¨¡å—è¿è¡Œæ­£å¸¸ï¼")

if __name__ == "__main__":
    test_rustbpe()