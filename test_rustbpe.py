import rustbpe
import time

def test_rustbpe():
    print("ğŸ” å¼€å§‹æµ‹è¯• rustbpe æ¨¡å—...")
    
    # 1. å®ä¾‹åŒ–
    try:
        tokenizer = rustbpe.Tokenizer()
        print("âœ… Tokenizer å®ä¾‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å®ä¾‹åŒ–å¤±è´¥: {e}")
        return

    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®
    # åˆ¶é€ ä¸€äº›é‡å¤æ¨¡å¼ä»¥ä¾¿ BPE èƒ½å¤Ÿå­¦ä¹ åˆ°åˆå¹¶è§„åˆ™
    data = [
        "hello world " * 20,
        "hello python " * 20,
        "rust is fast " * 20,
        "learning ai infra is cool " * 20
    ]
    
    # 3. è®­ç»ƒ
    # è¯è¡¨å¤§å°è®¾ä¸º 300 (åŸºç¡€ 256 å­—èŠ‚ + 44 ä¸ªåˆå¹¶è§„åˆ™)
    print("â³ å¼€å§‹è®­ç»ƒ (vocab_size=300)...")
    t0 = time.time()
    try:
        # train_from_iterator(iterator, vocab_size, buffer_size, pattern)
        tokenizer.train_from_iterator(data, 300)
        dt = time.time() - t0
        print(f"âœ… è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {dt:.4f}s")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return

    # 4. ç¼–ç æµ‹è¯•
    test_str = "hello world rust is cool"
    try:
        ids = tokenizer.encode(test_str)
        print(f"âœ… ç¼–ç ç»“æœ: '{test_str}' -> {ids}")
        
        # ç®€å•éªŒè¯ï¼šå¦‚æœæœ‰åˆå¹¶å‘ç”Ÿï¼Œtoken æ•°é‡åº”è¯¥å°‘äºå­—ç¬¦æ•°é‡
        # (æ³¨æ„ï¼šè¿™é‡Œä¸ä¸€å®šä¸¥æ ¼å°äºï¼Œå–å†³äºè®­ç»ƒæ•°æ®æ˜¯å¦è¦†ç›–äº†æµ‹è¯•å¥å­çš„æ¨¡å¼ï¼Œä½†å¤§æ¦‚ç‡ä¼šå˜çŸ­)
        print(f"   åŸå§‹é•¿åº¦: {len(test_str)}, Token æ•°é‡: {len(ids)}")
    except Exception as e:
        print(f"âŒ ç¼–ç å¤±è´¥: {e}")
        return

    print("\nğŸ‰ æ­å–œï¼Rust Tokenizer æ¨¡å—è¿è¡Œæ­£å¸¸ï¼")

if __name__ == "__main__":
    test_rustbpe()